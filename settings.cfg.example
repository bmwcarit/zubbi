# global configuration
ES_HOST = '<elasticsearch_host>'
ES_PORT = 9200
ES_USER = 'user'
ES_PASSWORD = 'password'

# Scraper configuration
# NOTE: The connection names must go in hand with the ones used in the tenant
# configuration
CONNECTIONS = {
    # GitHub example
    '<name>': {
        'provider': 'github',
        'url': 'https://github.com',
        'app_id': 0,
        'app_key': '<path_to_keyfile>',
    },
    # Gerrit example
    '<name>': {
        'provider': 'gerrit',
        'url': '<git_remote_url>',
        # Only necessary if different from the git_remote_url
        'web_url': '<gerrit_url>',
        'user': '<username>',
        'password': '<password',
    }
}

GITHUB_WEBHOOK_SECRET = '<secret>'
# NOTE: Use only one of the following, not both
TENANT_SOURCES_REPO = '<orga>/<repo>'
TENANT_SOURCES_FILE = 'example.main.yaml'

ZMQ_PUB_SOCKET_ADDRESS = 'tcp://*:5556'
ZMQ_SUB_SOCKET_ADDRESS = 'tcp://localhost:5556'
# Timeout in milliseconds (5 min)
ZMQ_SUB_TIMEOUT = 300000
# Interval after which a repo will be scraped in any case (in hours)
FORCE_SCRAPE_INTERVAL = 24
